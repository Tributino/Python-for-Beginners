{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1><center> Week 7 - Assignment </center></h1>\n",
    "\n",
    "<h2><center> WIM250/WDIM150 - Introduction to Scripting Languages</center></h2>\n",
    "<h3><center>Instructor: Ivaldo Tributino</center></h3>\n",
    "\n",
    "**Assignment Instruction**\n",
    "\n",
    "- The assignment must be submitted by **May 22, 2022**.\n",
    "- Each problem presents its own score, the sum of all scores is **100**.\n",
    "- **Renamed** the Notebook to your name,\n",
    "- You must submit your`.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "student_name = ''           \n",
    "student_number = ''         \n",
    "\n",
    "print('''By attempting this assignment, I, %s, acknowledge that I have read and understand the \n",
    "conduct requirements for this activity, and I understand that submitting anotherâ€™s \n",
    "work as my own can result in grade zero for this assignment. \n",
    "'''%student_name)\n",
    "\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "van = timezone('America/Vancouver')\n",
    "datetime_Van = datetime.now(van)\n",
    "\n",
    "print(\"Vancouver time:\", datetime_Van.strftime(\"%c\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5 points)\n",
    "**1. Find out which environment jupyter is running by running the cell below.** (You can use any environment, as long as you have installed the necessary libraries to work on our activities.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (15 points) \n",
    "\n",
    "**2. Show that you have installed the `requests` library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "print(requests.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (15 points) \n",
    "\n",
    "**3. Show that you have installed the `Beautiful Soup` library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "print(bs4.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (20 points)\n",
    "\n",
    "**4. Explain in detail what the program below is doing and present its output.**\n",
    "\n",
    "```python\n",
    "html_doc = \"\"\"<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "    \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup1 = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "for link in soup1.find_all('a'):   \n",
    "    print(link.get('href')) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (20 points)\n",
    " \n",
    "**5. Explain why in the following example it is necessary to use the `requests` library, on the other hand, it is unnecessary in the above program. Also presents its output.** \n",
    "\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://nostarch.com'\n",
    "res = requests.get(url)        \n",
    "res.raise_for_status()\n",
    "  \n",
    "soup2 = BeautifulSoup(res.text, 'html.parser') \n",
    "for link in soup2.find_all('link'):   \n",
    "    print(link.get('href'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (25 points)\n",
    "\n",
    "**6. Now it's your turn, find a site that you have interesting, extract some data from it using the libraries `Requests` and` Beautiful Soup`. You can use methods like `find_all()`, `select()` or any others that were not present in the class activity Notebook.**\n",
    "\n",
    "Use rob robots.txt to verify that you can scraping the website. For more information, see https://medium.com/ub-women-data-scholars/let-the-robot-do-your-work-web-scraping-with-python-9c147fb7690f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
